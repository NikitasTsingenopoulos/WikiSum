{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikitasTsingenopoulos/WikiSum/blob/main/WikiSum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DjeB_DRE4Cfp"
      },
      "outputs": [],
      "source": [
        "!pip install -U datasets\n",
        "!pip install -U evaluate\n",
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bert-score"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FwSECKmyBUre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWpCEWAX36PS"
      },
      "outputs": [],
      "source": [
        "from transformers import (AutoTokenizer, LEDConfig, LEDForConditionalGeneration)\n",
        "from datasets import load_dataset, Dataset\n",
        "import torch\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ozDKDiiaG4l8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bert_score import score\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "GwVAlh28BMwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download"
      ],
      "metadata": {
        "id": "MM6vQqZH279P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_id = \"d0rj/wikisum\"\n",
        "splits = {'train': 'data/train-00000-of-00001-b28959cff7dcaf55.parquet', 'validation': 'data/validation-00000-of-00001-21f2c9acfa77bab4.parquet', 'test': 'data/test-00000-of-00001-52a8a7cd640a9fff.parquet'}"
      ],
      "metadata": {
        "id": "VhzGRInt2_8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = pd.read_parquet(hf_hub_download(repo_id=repo_id, repo_type=\"dataset\", filename=splits[\"train\"]))\n",
        "dataset_val = pd.read_parquet(hf_hub_download(repo_id=repo_id, repo_type=\"dataset\", filename=splits[\"validation\"]))\n",
        "dataset_test = pd.read_parquet(hf_hub_download(repo_id=repo_id, repo_type=\"dataset\", filename=splits[\"test\"]))"
      ],
      "metadata": {
        "id": "Dj-1GW1U6Fkr",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNInV_G2NB1n"
      },
      "outputs": [],
      "source": [
        "dataset_train = Dataset.from_pandas(dataset_train)\n",
        "dataset_val = Dataset.from_pandas(dataset_val)\n",
        "dataset_test = Dataset.from_pandas(dataset_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdq-BfpF4vfE",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('allenai/PRIMERA')\n",
        "\n",
        "config=LEDConfig.from_pretrained('allenai/PRIMERA')\n",
        "\n",
        "model = LEDForConditionalGeneration.from_pretrained('allenai/PRIMERA')\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "PAD_TOKEN_ID = tokenizer.pad_token_id\n",
        "DOCSEP_TOKEN_ID = tokenizer.convert_tokens_to_ids(\"<doc-sep>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qALhkexu5Bq2"
      },
      "outputs": [],
      "source": [
        "def process_document(documents):\n",
        "    input_ids_all = []\n",
        "\n",
        "    for data in documents:\n",
        "        cleaned_text = \" \".join(data.replace(\"\\n\", \" \").split())\n",
        "        input_chunks = [cleaned_text]\n",
        "\n",
        "        input_ids = []\n",
        "        for doc in input_chunks:\n",
        "            input_ids.extend(\n",
        "                tokenizer.encode(\n",
        "                    doc,\n",
        "                    truncation=True,\n",
        "                    max_length=4096,\n",
        "                )[1:-1]\n",
        "            )\n",
        "            input_ids.append(DOCSEP_TOKEN_ID)\n",
        "\n",
        "        input_ids = (\n",
        "            [tokenizer.bos_token_id]\n",
        "            + input_ids\n",
        "            + [tokenizer.eos_token_id]\n",
        "        )\n",
        "        input_ids_all.append(torch.tensor(input_ids))\n",
        "\n",
        "    input_ids = torch.nn.utils.rnn.pad_sequence(\n",
        "        input_ids_all, batch_first=True, padding_value=PAD_TOKEN_ID\n",
        "    )\n",
        "    return input_ids"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bert_apply(generated, reference_summary):\n",
        "    summary_sents = sent_tokenize(generated)\n",
        "    # Create a list of the same reference summary, repeated for each candidate sentence\n",
        "    reference = [reference_summary] * len(summary_sents)\n",
        "\n",
        "    # Score sentences\n",
        "    P, R, F1 = score(summary_sents, reference, lang=\"en\", verbose=True)\n",
        "\n",
        "    # Rank and select top N\n",
        "    ranked = sorted(zip(summary_sents, F1), key=lambda x: x[1], reverse=True)\n",
        "    concise_summary = \" \".join([sent for sent, _ in ranked[:4]])\n",
        "    return concise_summary"
      ],
      "metadata": {
        "id": "2-7dbSLfDHNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hr6v9Oei5gVi"
      },
      "outputs": [],
      "source": [
        "def batch_process(batch):\n",
        "    input_ids=process_document(batch['article'])\n",
        "    # get the input ids and attention masks together\n",
        "    global_attention_mask = torch.zeros_like(input_ids).to(input_ids.device)\n",
        "    # put global attention on <s> token\n",
        "\n",
        "    global_attention_mask[:, 0] = 1\n",
        "    global_attention_mask[input_ids == DOCSEP_TOKEN_ID] = 1\n",
        "    generated_ids = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        global_attention_mask=global_attention_mask,\n",
        "        use_cache=True,\n",
        "        max_length=512,\n",
        "        min_length=50,\n",
        "        num_beams=5,\n",
        "        length_penalty=2,\n",
        "        no_repeat_ngram_size=3,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    generated_str = tokenizer.batch_decode(\n",
        "            generated_ids.tolist(), skip_special_tokens=True\n",
        "        )\n",
        "\n",
        "    generated_str_bert = [bert_apply(generated, ref) for generated, ref in zip(generated_str, batch['summary'])]\n",
        "\n",
        "    result={}\n",
        "    result['generated_summaries'] = generated_str_bert\n",
        "    result['gt_summaries']=batch['summary']\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMlPQOR8cUc5"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "docs = random.sample(range(len(dataset_test)),k=5)\n",
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yppYQ4VB5qEI",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "dataset_small = dataset_test.select(docs)\n",
        "result_small = dataset_small.map(batch_process, batched=True, batch_size=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEMbGp0U5r5o"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4HZgx5J6H4b"
      },
      "outputs": [],
      "source": [
        "rouge_scores = rouge.compute(predictions=result_small[\"generated_summaries\"], references=result_small[\"gt_summaries\"])\n",
        "\n",
        "print(f\"ROUGE-1: {rouge_scores['rouge1']:.4f}\")\n",
        "print(f\"ROUGE-2: {rouge_scores['rouge2']:.4f}\")\n",
        "print(f\"ROUGE-L: {rouge_scores['rougeL']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcSANiO6-Jjj"
      },
      "outputs": [],
      "source": [
        "for i in range(0,5):\n",
        "    example_summ = dataset_small[i]['summary']\n",
        "    produced_summ = result_small[i]['generated_summaries']\n",
        "    display(example_summ)\n",
        "    display(produced_summ)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LbsiDnOw_GI9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOocY5UrnuZ2xrsJgxWhPo0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}